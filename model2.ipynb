{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Htg0QJV-2g8p"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models import resnet18\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1eUvpSnM2o2B"
   },
   "outputs": [],
   "source": [
    "# Define the path to the dataset\n",
    "data_dir = \"affectnet\"\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "test_dir = os.path.join(data_dir, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ki7Uftvl2tjX"
   },
   "outputs": [],
   "source": [
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((48, 48)),  # Resize images to a fixed size\n",
    "    transforms.ToTensor(),          # Convert images to tensors\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize the images\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6P0kRnrp20nz"
   },
   "outputs": [],
   "source": [
    "# Custom Dataset class to load images and labels\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.dataset = ImageFolder(data_dir, transform=transform)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.dataset[idx]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "blJCHJkN20zR"
   },
   "outputs": [],
   "source": [
    "# Create train and test datasets\n",
    "train_dataset = CustomDataset(train_dir, transform=transform)\n",
    "test_dataset = CustomDataset(test_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "K-5Qum6S_8n-"
   },
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JpJxwSBv2058"
   },
   "outputs": [],
   "source": [
    "# Define the emotion categories\n",
    "emotion_categories = {\n",
    "    1: \"Neutral\",\n",
    "    2: \"Happiness\",\n",
    "    3: \"Sadness\",\n",
    "    4: \"Surprise\",\n",
    "    5: \"Afraid\",\n",
    "    6: \"Disgusted\",\n",
    "    7: \"Angry\",\n",
    "    8: \"Contempt\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "vV0-lLtk6Dev"
   },
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class EmotionCNN(nn.Module):\n",
    "    def __init__(self, num_classes=8):\n",
    "        super(EmotionCNN, self).__init__()\n",
    "        self.resnet = resnet18(pretrained=True)\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.resnet.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "atgyjroH6Gim"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\03aay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\users\\03aay\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EmotionCNN(num_classes=8).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l8937eIy6Gp2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20] Loss: 2.010980660374831\n",
      "Epoch [2/20] Loss: 1.7693768812094623\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {running_loss/len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p_tNRLg_6GtA"
   },
   "outputs": [],
   "source": [
    "# Evaluation on the test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "all_predicted = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        all_predicted.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "print(f\"Accuracy on test set: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8PaTI4uzxo9K"
   },
   "outputs": [],
   "source": [
    "# Create a confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_predicted)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mHk4_MQJxp4H"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "snatdTW4yCev"
   },
   "outputs": [],
   "source": [
    "# Save the model to an h5 file\n",
    "torch.save(model.state_dict(), \"emotion_recognition_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UzHmtCzv6Gx_"
   },
   "outputs": [],
   "source": [
    "# Function to decode emotion labels\n",
    "def decode_emotion_label(label):\n",
    "    return emotion_categories[label]\n",
    "\n",
    "# Example usage of decoding labels\n",
    "example_label = 1\n",
    "print(f\"Emotion Category for label {example_label}: {decode_emotion_label(example_label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CVCwTRH26G0y"
   },
   "outputs": [],
   "source": [
    "# Function to create a radar chart for emotion categories and probabilities\n",
    "def radar_chart_for_image(model, image):\n",
    "    model.eval()\n",
    "    image = image.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(image.unsqueeze(0))\n",
    "        probabilities = torch.softmax(output, dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "    angles = np.linspace(0, 2 * np.pi, len(emotion_categories), endpoint=False)\n",
    "    angles = np.concatenate((angles, [angles[0]]))\n",
    "    probabilities = np.concatenate((probabilities, [probabilities[0]]))\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = fig.add_subplot(111, polar=True)\n",
    "    ax.plot(angles, probabilities, 'o-', linewidth=2)\n",
    "    ax.fill(angles, probabilities, alpha=0.25)\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(list(emotion_categories.values()))\n",
    "    ax.set_title(\"Emotion Probabilities\", fontsize=14)\n",
    "    ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_18AA1UyGG3"
   },
   "outputs": [],
   "source": [
    "# Load the first image from the test set\n",
    "sample_image, sample_label = test_dataset[0]\n",
    "\n",
    "# Display the image\n",
    "sample_image.show()\n",
    "\n",
    "# Create the radar chart for the image's emotion probabilities\n",
    "radar_chart_for_image(model, sample_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
