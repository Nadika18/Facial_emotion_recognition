{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LhPptKjhqV2N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "821e4f89-8680-400d-ff31-909fd6c890d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to access data\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Htg0QJV-2g8p"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir('/content'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "silx3H9o4EQY",
        "outputId": "247a04c2-30e4-453f-fc78-c3508fbac386"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'drive', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the dataset\n",
        "train_dir = '/content/drive/MyDrive/affectnet/train'\n",
        "test_dir = '/content/drive/MyDrive/affectnet/test'"
      ],
      "metadata": {
        "id": "1eUvpSnM2o2B"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((48, 48)),  # Resize images to a fixed size\n",
        "    transforms.ToTensor(),          # Convert images to tensors\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize the images\n",
        "])\n"
      ],
      "metadata": {
        "id": "Ki7Uftvl2tjX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Dataset class to load images and labels\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.dataset = ImageFolder(data_dir, transform=transform)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.dataset[idx]\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "6P0kRnrp20nz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train and test datasets\n",
        "train_dataset = CustomDataset(train_dir, transform=transform)\n",
        "test_dataset = CustomDataset(test_dir, transform=transform)"
      ],
      "metadata": {
        "id": "blJCHJkN20zR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loaders\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "s0ZuCd3fZCEC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the emotion categories\n",
        "emotion_categories = {\n",
        "    1: \"Neutral\",\n",
        "    2: \"Happiness\",\n",
        "    3: \"Sadness\",\n",
        "    4: \"Surprise\",\n",
        "    5: \"Afraid\",\n",
        "    6: \"Disgusted\",\n",
        "    7: \"Angry\",\n",
        "    8: \"Contempt\"\n",
        "}"
      ],
      "metadata": {
        "id": "JpJxwSBv2058"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the custom CNN model\n",
        "class EmotionCNN(nn.Module):\n",
        "    def __init__(self, num_classes=8):\n",
        "        super(EmotionCNN, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(128 * 6 * 6, 512),  # Adjusted input size (128 * 6 * 6)\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "vV0-lLtk6Dev"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model and optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = EmotionCNN(num_classes=8).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "atgyjroH6Gim"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {running_loss/len(train_loader)}\")"
      ],
      "metadata": {
        "id": "l8937eIy6Gp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on the test set\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "all_predicted = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        all_predicted.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "print(f\"Accuracy on test set: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "id": "p_tNRLg_6GtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a confusion matrix\n",
        "conf_matrix = confusion_matrix(all_labels, all_predicted)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "id": "bWp4HOKZZfhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(conf_matrix)"
      ],
      "metadata": {
        "id": "WdeZvyVUZflS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model to an h5 file\n",
        "torch.save(model.state_dict(), \"model3.h5\")"
      ],
      "metadata": {
        "id": "IrGsG7XJZqbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to decode emotion labels\n",
        "def decode_emotion_label(label):\n",
        "    return emotion_categories[label]\n",
        "\n",
        "# Example usage of decoding labels\n",
        "example_label = 1\n",
        "print(f\"Emotion Category for label {example_label}: {decode_emotion_label(example_label)}\")"
      ],
      "metadata": {
        "id": "UzHmtCzv6Gx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create a radar chart for emotion categories and probabilities\n",
        "def radar_chart_for_image(model, image):\n",
        "    model.eval()\n",
        "    image = image.to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(image.unsqueeze(0))\n",
        "        probabilities = torch.softmax(output, dim=1).squeeze().cpu().numpy()\n",
        "\n",
        "    angles = np.linspace(0, 2 * np.pi, len(emotion_categories), endpoint=False)\n",
        "    angles = np.concatenate((angles, [angles[0]]))\n",
        "    probabilities = np.concatenate((probabilities, [probabilities[0]]))\n",
        "\n",
        "    fig = plt.figure(figsize=(6, 6))\n",
        "    ax = fig.add_subplot(111, polar=True)\n",
        "    ax.plot(angles, probabilities, 'o-', linewidth=2)\n",
        "    ax.fill(angles, probabilities, alpha=0.25)\n",
        "    ax.set_xticks(angles[:-1])\n",
        "    ax.set_xticklabels(list(emotion_categories.values()))\n",
        "    ax.set_title(\"Emotion Probabilities\", fontsize=14)\n",
        "    ax.grid(True)\n"
      ],
      "metadata": {
        "id": "CVCwTRH26G0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "# Load the first image from the test set\n",
        "sample_image, sample_label = test_dataset[0]\n",
        "\n",
        "# Display the image\n",
        "sample_image.show()\n",
        "\n",
        "# Create the radar chart for the image's emotion probabilities\n",
        "radar_chart_for_image(model, sample_image)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5kroqF-NZ9ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LcnDdDxSCMm0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}